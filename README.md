# Machine Learning Attack Series - Overview

![Machine Learning Attack Series](https://embracethered.com/blog/images/2020/ml-attack-series.jpg)

The code for the Husky AI server and model files are [here](https://github.com/wunderwuzzi23/huskyai).

## Machine Learning Basics and Building Husky AI

* [Getting the hang of machine learning](https://embracethered.com/blog/posts/2020/machine-learning-basics/)
* [The machine learning pipeline and attacks](https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/)
* [Husky AI: Building a machine learning system](https://embracethered.com/blog/posts/2020/husky-ai-building-the-machine-learning-model/)
* [MLOps - Operationalizing the machine learning model](https://embracethered.com/blog/posts/2020/husky-ai-mlops-operationalize-the-model/)

## Threat Modeling and Strategies 

* [Threat modeling a machine learning system](https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/)
* [Grayhat Red Team Village Video: Building and breaking a machine learning system](https://www.youtube.com/watch?v=-SV80sIBhqY)
* [Assume Bias and Responsible AI](https://embracethered.com/blog/posts/2020/machine-learning-attack-series-assume-bias-strategy/) 

## Practical Attacks and Defenses

* [Brute forcing images to find incorrect predictions](https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-bruteforce/) 
* [Smart brute forcing](https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-smart-fuzz/) 
* [Perturbations to misclassify existing images](https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-attack-perturbation-external/) 
* [Adversarial Robustness Toolbox Basics](https://embracethered.com/blog/posts/2020/husky-ai-adversarial-robustness-toolbox-testing/)
* [Image Scaling Attacks](https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/)
* [Stealing a model file: Attacker gains read access to the model](https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-model-stealing/) 
* [Backdooring models: Attacker modifies persisted model file](https://embracethered.com/blog/posts/2020/husky-ai-machine-learning-backdoor-model/)
* [Repudiation Threat and Auditing: Catching modifications and unauthorized access](https://embracethered.com/blog/posts/2020/husky-ai-repudiation-threat-deny-action-machine-learning/)
* [Attacker modifies Jupyter Notebook file to insert a backdoor](https://embracethered.com/blog/posts/2020/cve-2020-16977-vscode-microsoft-python-extension-remote-code-execution/)
* [CVE 2020-16977: VS Code Python Extension Remote Code Execution](https://embracethered.com/blog/posts/2020/cve-2020-16977-vscode-microsoft-python-extension-remote-code-execution/)
* [Using Generative Adversarial Networks (GANs) to create fake husky images](https://embracethered.com/blog/posts/2020/machine-learning-attack-series-generative-adversarial-networks-gan/)
* [Using Azure Counterfit to create adversarial examples](https://embracethered.com/blog/posts/2021/huskyai-using-azure-counterfit/)

## Miscellaneous

* [Participating in the Microsoft Machine Learning Security Evasion Competition - Bypassing malware models by signing binaries](https://embracethered.com/blog/posts/2020/microsoft-machine-learning-security-evasion-competition/)
* [Husky AI Github Repo](https://github.com/wunderwuzzi23/huskyai/)


*Reminder: Penetration testing requires authorization from proper stakeholders. Information is provided for research and educational purposes to advance understanding of attacks and improve countermeasures.*
